{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When you are working, usually you will want to use data from internet. Sometimes you can find data in friendly format like csv or xlsx or sometimes you can access the data via API (Application Programming Interface)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### But sometimes the only way to access the data is using a technique call Web Scrapin. This technique allow you to get the data from the web into a format you can work with in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First of all we need to understand what we are going to find in a web page so let's see a short summary of it !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The components of a web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When the data is donwloaded from the web page, falls into some categories. The main categories are:\n",
    "- HTML: Contain the main content of the web page.\n",
    "- CSS: Contain the instructions to make the web page looks beauty.\n",
    "- JavaScript: Contain the instruction to add interactivity into the web page. \n",
    "- Images: Allos the web page to show pictures in formats like JPG, PNG, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We will focus on the HTML code. Here is where the data that we want to obtain is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML (Tags < > )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When you perform web scraping you have to deal with tags. Some of the most usual tags that you wil found in html code are listed below.\n",
    "- 'html': Html document is contained into this tags.\n",
    "- 'body': Inside html tag, body tags contain all the visible elements that the web page shows to the user.\n",
    "- 'p': Inside the body tag, p tags contain a paragraph. Each p tag contain one paragraph.\n",
    "- 'a': Inside the body tag, a tags contain a link to other web page.\n",
    "- 'table': Inside the body tag, a table tag contain a table. Each row is contained into a 'tr' tag and rows are divided into data as 'td'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Python is an open source programming language so there are a lot of libraries to perform the same action. In this training we are going to use a few libraries to explain how to do web scraping:\n",
    "- Request: We will use the \"get\" function to obtain the html code from the web page. (this library have a lot of other functions)\n",
    "- BeautyfulSoup: This library allow you to clean the html code to obtain just the data that you want.\n",
    "- Parsel: This library gives you another way to extract the data from the html code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now ... hands on the code !! (finally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we need to import the request library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can print the content of the web page using the content function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### And then you can use the BeautyfulSoup to parse the downloaded content of the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we can use the prettify method in our BeautyfulSoup object to see the html code in a really better undertanding way than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### With the previous code you can see the nested tags. Now is time to start digging into the tags to extract the paragraph that we want.\n",
    "###### We can use the children method to get into the nested tags one level at a time. Note that the children method returns a list with the nested tags so we need to use the list function to see the nested tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x1f8770d9e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html', '\\n', <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We found 3 elements using the children method. We can see the type of the elements using the type function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.NavigableString, bs4.element.Tag]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first element is a Doctype object which contain information about the type of the document\n",
    "- The second element is a NavegableString which is text found in the code\n",
    "- And finally the last element is a Tag object. This is the object what we are looking for because this object contains the other tags and the information that we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can now select the html tag saving the last element of the previous list into a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[2]\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Each one of the returned items by the children method are also a BeautyfulSoup object so we can use the children method with those returned items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So here we go again !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <head>\n",
       " <title>A simple example page</title>\n",
       " </head>, '\\n', <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>, '\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we have 5 elements. Three of them are just text. The other two elements are the Head tag and the Body tag which contain the p tag that we want to extract (We are almost there!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So we have to repeat the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = list(html.children)[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### And now our last effort to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Here is some simple content for this page.</p>, '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(body.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = list(body.children)[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We finally have the p tag in our pocket so to get the content of the p tag we need to use the get_text method in our variable to extract all of the text from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We did it !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can now learn a better way to do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all instances of a tag at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All the previous steps was needed to make you understand how to navigate through a web page and get the data that you want, but as you can see it take us a lot of code and effort to get the data.\n",
    "###### There is another way to do the same. We can use the find_all method to get all the instances of a tag in just one shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note that find_all method returns a list of elements so we need to use an index to extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In case you want to get just the first element in the html code of a particular tag, you can use the 'find' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note that the previous output is not a list so you should use the get_text method without using index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for tags using class and id attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Class and Id are two attributes that can be included in html code.\n",
    "- Class attribute allow you to categorize one or more elements into groups\n",
    "- Id attribute allow you to identify an element. A certain Id can be used by just one element and an element can have just one Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can use this attibutes when we are scraping to get particular elements in our searchs so we can filter effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To understand this we are going to use the following web page: http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we are going to search for any p tag that has the class outer-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You can also search for elemetns using the Id attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When you are searching for elements you can also do it using CSS selectors. Remember that CSS language allows developers to specify html tags to style. Here you have some examples:\n",
    "- p a : finds all \"a\" tags inside of a \"p\" tag\n",
    "- body p a : finds all \"a\" tags inside of a \"p\" tag inside of a \"body\" tag\n",
    "- html body : finds all \"body\" tags inside of an \"html\" tag\n",
    "- p.outer-text : finds all \"p\" tags with a class of \"outer-text\"\n",
    "- p#first : finds all \"p\" tags with an id of \"first\"\n",
    "- body p.outer-text : finds any \"p\" tags with a class of \"outer-text\" inside of a \"body\" tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The great thing is that BeautyfulSoup objects support searching a web page via CSS selectors. The only difference is that you have to use the select method.\n",
    "###### Note that select method returns a list of elements as equal as find and find_all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>, <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parsel is a python library for extracting data from XML/HTML text using CSS or XPath selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In this case we are going to use the following html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = u'''\n",
    "<ul>\n",
    "    <li><a href=\"http://blog.scrapinghub.com\">Blog</a></li>\n",
    "...\n",
    "    <li><a href=\"https://www.scrapinghub.com\">Scrapinghub</a></li>\n",
    "...\n",
    "    <li class=\"external\"><a href=\"http://www.scrapy.org\">Scrapy</a></li>\n",
    "</ul>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we have to import the Parsel library, load it into a Parsel Selector and extract links with an XPath expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://blog.scrapinghub.com',\n",
       " 'https://www.scrapinghub.com',\n",
       " 'http://www.scrapy.org']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import parsel\n",
    "sel = parsel.Selector(html)\n",
    "sel.xpath(\"//a/@href\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### One of the best features of Parsel is the ability to chain selectors !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.scrapy.org']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('li.external').xpath('./a/@href').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You can also iterate through the results of the .css() and .xpath() methods since each element will be another selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://blog.scrapinghub.com\n",
      "https://www.scrapinghub.com\n",
      "http://www.scrapy.org\n"
     ]
    }
   ],
   "source": [
    "for li in sel.css('ul li'):\n",
    "    print(li.xpath('./a/@href').extract_first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
